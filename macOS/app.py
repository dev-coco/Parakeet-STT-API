# -*- coding: utf-8 -*-

# ç¦ç”¨ TorchScriptï¼Œé¿å…å†»ç»“å JIT è¯»å–æºç å¯¼è‡´ OSError
import os
os.environ["PYTORCH_JIT"] = "0"

import sys
import tempfile
import time
import gc
import logging
import threading
import subprocess
import numpy as np
from flask import Flask, request, jsonify
from werkzeug.utils import secure_filename
import librosa
import soundfile as sf

# è¿è¡Œæ—¶èµ„æºæ ¹ç›®å½•
def _get_base_dir() -> str:
    if getattr(sys, "frozen", False):
        return getattr(sys, "_MEIPASS", os.path.dirname(sys.executable))
    return os.path.abspath(os.path.dirname(__file__))

BASE_DIR = _get_base_dir()

# æ¨¡å‹ä¸ç¼“å­˜ç›®å½•
MODELS_DIR = os.path.join(BASE_DIR, "models")
os.environ["HF_HOME"] = MODELS_DIR

# Nemo æ¨¡å‹
# NEMO_BUNDLE = os.path.join(MODELS_DIR, "parakeet-tdt-0.6b-v3.nemo")
FFMPEG_PATH = os.path.join(BASE_DIR, "ffmpeg/ffmpeg")

# å±è”½å†—ä½™æ—¥å¿—
logging.getLogger("torch.distributed.elastic").setLevel(logging.ERROR)
logging.disable(logging.CRITICAL)

print("æ­£åœ¨å¯åŠ¨ä¸­")
print("ğŸš€ æ­£åœ¨åŠ è½½ ASR æ¨¡å‹ï¼ˆä»…é¦–æ¬¡æ‰§è¡Œï¼‰...")

# æ·±åº¦å­¦ä¹ ä¾èµ–æ”¾åœ¨ç¯å¢ƒå˜é‡è®¾ç½®ä¹‹åå†å¯¼å…¥
import torch
import nemo.collections.asr as nemo_asr

# 8) åŠ è½½ Nemo ASR æ¨¡å‹
# ASR_MODEL = nemo_asr.models.ASRModel.restore_from(NEMO_BUNDLE)
ASR_MODEL = nemo_asr.models.ASRModel.from_pretrained("nvidia/parakeet-tdt-0.6b-v3")
ASR_MODEL.eval()
print("âœ… æ¨¡å‹åŠ è½½å®Œæˆï¼Œå‡†å¤‡å°±ç»ªã€‚")

# 9) Flask åº”ç”¨
app = Flask(__name__)

def memory_stats():
    """æ‰“å°å½“å‰CUDAæ˜¾å­˜ä½¿ç”¨æƒ…å†µï¼Œç”¨äºè°ƒè¯•å†…å­˜å ç”¨"""
    if torch.cuda.is_available():
        print('Memory allocated:', torch.cuda.memory_allocated() / 1024 ** 2, 'MB')
        print('Memory cached:', torch.cuda.memory_reserved() / 1024 ** 2, 'MB\n')
    else:
        print("CUDA not available.\n")

def safe_json(obj):
    """é€’å½’å®‰å…¨è½¬æ¢numpyç±»å‹ä¸ºPythonåŸºç¡€ç±»å‹ï¼Œä¾¿äºJSONåºåˆ—åŒ–"""
    if isinstance(obj, dict):
        return {k: safe_json(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [safe_json(v) for v in obj]
    elif isinstance(obj, (np.integer, np.int64)):
        return int(obj)
    elif isinstance(obj, (np.floating, np.float32, np.float64)):
        return float(obj)
    elif isinstance(obj, np.ndarray):
        return obj.tolist()
    else:
        return obj

def transcribe_audio(audio_filepath):
    """
    ä½¿ç”¨å·²åŠ è½½çš„ASRæ¨¡å‹å¯¹ç»™å®šéŸ³é¢‘æ–‡ä»¶è¿›è¡Œè½¬å½•ï¼š
    1) ç”¨ ffmpeg è½¬å•å£°é“ 16kHz WAVï¼›
    2) librosa å¤æ ¸å¹¶é‡å†™ï¼›
    3) NeMo æ¨¡å‹è½¬å½•å¹¶è¿”å›ç»“æœã€‚
    """
    extracted_wav = None
    try:
        # ç”Ÿæˆä¸´æ—¶WAVæ–‡ä»¶è·¯å¾„
        extracted_wav = tempfile.NamedTemporaryFile(delete=False, suffix=".wav").name

        # ffmpeg è½¬ç 
        cmd = [
            FFMPEG_PATH, "-y", "-i", audio_filepath,
            "-ac", "1", "-ar", "16000", "-vn", "-loglevel", "error", extracted_wav
        ]
        subprocess.run(cmd, check=True)

        # librosa åŠ è½½å¤æ ¸å¹¶é‡å†™
        data, sr = librosa.load(extracted_wav, sr=16000, mono=True)
        sf.write(extracted_wav, data, sr)

        # è¯­éŸ³è¯†åˆ«
        print("ğŸ§  å¼€å§‹è¯­éŸ³è¯†åˆ«...")
        start = time.time()
        results = ASR_MODEL.transcribe([extracted_wav], timestamps=True)
        print(f"âœ… è¯†åˆ«å®Œæˆï¼Œç”¨æ—¶ {time.time() - start:.2f} ç§’")

        if not results:
            return {"error": "æ— è¯†åˆ«ç»“æœ"}

        r = results[0]
        text = getattr(r, 'text', "")
        timestamps = getattr(r, 'timestamp', {})
        return {"text": text, "timestamps": safe_json(timestamps)}

    except Exception as e:
        return {"error": str(e)}

    finally:
        # æ¸…ç†ä¸´æ—¶ä¸æ˜¾å­˜
        if extracted_wav and os.path.exists(extracted_wav):
            os.remove(extracted_wav)
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()

@app.route('/transcribe', methods=['POST'])
def transcribe():
    """
    æ¥æ”¶POSTè¯·æ±‚ï¼Œå¤„ç†ä¸Šä¼ çš„éŸ³é¢‘æ–‡ä»¶ï¼Œåå°çº¿ç¨‹è°ƒç”¨è½¬å½•å‡½æ•°é˜²æ­¢é˜»å¡ï¼Œè¶…æ—¶300ç§’
    """
    if 'audio' not in request.files:
        return jsonify({"error": "æœªæä¾›éŸ³é¢‘æ–‡ä»¶"}), 400

    file = request.files['audio']
    if file.filename == '':
        return jsonify({"error": "æ–‡ä»¶åä¸ºç©º"}), 400

    filename = secure_filename(file.filename)
    print(f"æ”¶åˆ°æ–‡ä»¶: {filename}")

    temp_filepath = None
    try:
        with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(filename)[1]) as tmp_file:
            file.save(tmp_file.name)
            temp_filepath = tmp_file.name

        print(f"éŸ³é¢‘å·²ä¿å­˜: {temp_filepath}")

        result_container = {}

        def worker():
            result_container["data"] = transcribe_audio(temp_filepath)

        thread = threading.Thread(target=worker)
        thread.start()
        thread.join(timeout=300)

        if thread.is_alive():
            print("âš ï¸ è½¬å½•è¶…æ—¶ï¼ˆ300ç§’ï¼‰")
            return jsonify({"error": "è½¬å½•è¶…æ—¶"}), 500

        result = result_container.get("data", {"error": "æœªçŸ¥é”™è¯¯"})
        return jsonify(result)

    except Exception as e:
        return jsonify({"error": str(e)}), 500

    finally:
        if temp_filepath and os.path.exists(temp_filepath):
            os.remove(temp_filepath)
            print(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶: {temp_filepath}")

if __name__ == '__main__':
    print("ğŸŒ Flask æœåŠ¡å™¨å¯åŠ¨ä¸­...")
    app.run(host='0.0.0.0', port=1643, debug=False)
